<!DOCTYPE html>

<html>
  <head>
    <title>Affine Website</title>
    <br id="index" hidden/>
    <meta charset="utf-8"/>
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="style.css">
  </head>

  <body>
    <div id="container">
      <h3>Written Work</h3>
      <p><a href="mphil_thesis.html">MPhil Thesis</a> on approximate variational inference in Gaussian processes when there is circulant structure present in the pseudo-point covariance matrix. The corresponding <a href="mphil_poster.html">poster</a> was presented to the course's industrial sponsors.</p>
      <p><a href=aabi_2016_paper.html>An extension</a> of the above MPhil thesis was accepted for <a href="aabi_2016_poster.html">poster presentation</a> at the NIPS workshop on Advances in Approximate Bayesian Inference.</p>

      <h3>Presentations</h3>
      <p><a href="resources/gaussian-affine-posterior.pdf">Conditioning in Gaussians is an Affine Transform</a>. A (very) short presentation on a cute result that I initially found surprising. This presentation is rather terse, but my current research agenda employs this result, so a more thorough explanation of this result will be available here in the near future. Many thanks to Wessel Bruinsma for sanity checking this result.</p>
      <p><a href="resources/learning-to-learn.pdf">Learning to Learn</a>: a presentation written and presented jointly with Siddharth Swaroop. Here we review a couple of themes in the nebulously-defined sub-field of ML known as "Learning to Learn" or "Meta-Learning". This presentation is not intended to provide extensive detail for any particular work, but rather to frame two research themes in the area of Learning to Learn in a concise manner.</p>
    </div>
  </body>
</html>
